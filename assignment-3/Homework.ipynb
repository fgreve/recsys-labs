{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Laboratorio 3\n",
    "\n",
    "> **Tiempo:** -\n",
    "\n",
    "> **Entrega de informe:** -\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instalación\n",
    "\n",
    "Para facilitar el proceso de instalación de esta actividad, trabajaremos con una máquina virtual que tendrá _casi_ todos los programas instalados.\n",
    "\n",
    "Como motor de máquinas virtuales usaremos [Virtual Box](https://www.virtualbox.org/wiki/Downloads). Desde ese link tendrán que descargar la versión que mejor se ajuste a su sistema operativo. Luego desde los servidores de la universidad deben descargar la [máquina virtual](http://niebla.ing.puc.cl/diplomadobigdata/Lab%202.ova) ya configurada.\n",
    "\n",
    "Finalmente debemos importar la máquina descargada dentro de Virtual Box, para ello deben seguir los siguientes pasos: Abrir virtual box > Archivo > Abrir servicio virtualizado, o bien `Crtl+I`.\n",
    "\n",
    "**Observación:** la contraseña del usuario configurado es _ubuntu_.\n",
    "\n",
    "Descargar este proyecto ya sea con `git` o mediante el botón de descargar y ejecutar `notebook`.\n",
    "\n",
    "```bash\n",
    "$ git clone https://github.com/stgolarrain/recsys-labs.git\n",
    "$ cd recsys-labs/assignment-3\n",
    "$ jupyter notebook\n",
    "```\n",
    "\n",
    "Si ya tienen el repositorio descargado en la máquina virtual, puedes actualizar el código del repositorio con el siguiente comando.\n",
    "\n",
    "```bash\n",
    "$ cd recsys-labs\n",
    "$ git pull origin master\n",
    "$ de assignment-3\n",
    "```\n",
    "\n",
    "Para más detalles de cómo utilizar git puedes revisar la documentación [git pull](https://git-scm.com/docs/git-pull).\n",
    "\n",
    "Una vez descargada e importada la máquina virtual, puedes instalar las dependencias ejecutando la siguiente celda."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Instalation setup\n",
    "! pip3 install nltk\n",
    "! pip3 install sklearn\n",
    "! pip3 install gensim\n",
    "! pip3 install pandas\n",
    "! pip3 install numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instrucciones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "En esta oportunidad tendrán que experimentar con la librería [gensim](https://radimrehurek.com/gensim/) para el modelamiento de tópicos latentes en textos. Gensim es una librería que implementa modelos de tópicos, específicamente tendrás que trabajar con [Latent Dirichlet Allocation (LDA)](https://en.wikipedia.org/wiki/Latent_Dirichlet_allocation). La librería también permite transformar texto no estructurado en diferentes representaciones vectoriales, tales como [TF-IDF](https://es.wikipedia.org/wiki/Tf-idf), y buscar similaridades mediante diferentes métricas de distancia.\n",
    "\n",
    "Este laboratorio se divide en las siguientes secciones:\n",
    "\n",
    "1. Preprocesamiento de Datos: en esta sección tendrás que descargar librerías de _Natural Language Tool Kit_, la cual implementa las funcines básicas necesarias para trabajar con texto (datos no estructurados) y transformarlos en una representación vectorial estructurada.\n",
    "2. Modelo de Recomendaciones: en la segunda sección tendrás que entrenar un modelo de tópicos latentes (LDA)\n",
    "3. Generar Recomendaciones: finalmente, tendrás que utilizar el modelo de tópicos para generar recomendaciones basadas en contenido para un usuario ficticio que ha consumido 3 documentos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Preprocesamiento de Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import nltk\n",
    "import sklearn\n",
    "import gensim\n",
    "import string\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix\n",
    "from collections import Counter\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer \n",
    "from gensim import corpora, models, similarities\n",
    "from sklearn.neighbors import NearestNeighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Antes de comenzar debemos descargar las librerías de lenguaje de [NLTK](https://www.nltk.org/), ejecutando la siguiente celda:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Download corpora\n",
    "nltk.download()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para comenzar cargaremos el set de datos en un _dataframe_ de _Pandas_, e imprimimos los 5 primeros registros para visualizar la estructura de los datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corpus_df = pd.read_csv('./dataset/corpus1.csv', sep='\\t', header=None, encoding='latin')\n",
    "corpus_df.columns = ['id', 'title', 'abstract']\n",
    "corpus_df = corpus_df[['id', 'title', 'abstract']]\n",
    "corpus_df[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lo siguiente es implementar una función que transforme texto no estructurado a una lista de _tokens_ procesados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stemm = False\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "def get_tokens(text):\n",
    "    lowers = text.lower()\n",
    "    no_punctuation = lowers.translate(string.punctuation)\n",
    "    tokens = nltk.word_tokenize(no_punctuation)\n",
    "    if stemm:\n",
    "        tokens = map(stemmer.stem, tokens)\n",
    "    return tokens\n",
    "\n",
    "get_tokens(\"I'm a super student for recommender systems!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pregunta** Explique en sus palabras qué hace la función `get_tokens()`\n",
    "\n",
    "**Respuesta**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora se tiene que generar un diccionario con todas las palabras del _corpus_. Se recomiendo revisar la documentación de gensim y leer cómo usar los diccionarios. [corpora.dictionary](https://radimrehurek.com/gensim/corpora/dictionary.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dic_file = './resources/dictionary-stemm.p' if stemm else './resources/dictionary.p'\n",
    "if os.path.isfile(dic_file):\n",
    "    dictionary = corpora.dictionary.Dictionary().load(dic_file)\n",
    "else:\n",
    "    dictionary = corpora.dictionary.Dictionary(documents=corpus_df.tokenised_abstract.tolist())\n",
    "    dictionary.save(dic_file)\n",
    "    \n",
    "corpus_df['tokenised_abstract'] = corpus_df.abstract.map(get_tokens)\n",
    "corpus_df[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pregunta** Explique a qué corresponde la columan tokenised_abstract del dataframe\n",
    "\n",
    "**Respuesta**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corpus_df['bow'] = corpus_df.tokenised_abstract.map(dictionary.doc2bow)\n",
    "del corpus_df['tokenised_abstract']\n",
    "corpus = corpus_df['bow'].tolist()\n",
    "corpus_df[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pregunta** Explicar a qué corresponde la columna _bow_\n",
    "\n",
    "**Respuesta**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Modelo de Tópicos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tfidf_model_file = 'resources/tfidf_model-stemm.p' if stemm else 'resources/tfidf_model.p'\n",
    "if os.path.isfile(tfidf_model_file):\n",
    "    tfidf_model = models.tfidfmodel.TfidfModel().load(tfidf_model_file)\n",
    "else:\n",
    "    tfidf_model = models.tfidfmodel.TfidfModel(corpus, dictionary=dictionary)\n",
    "    tfidf_model.save(tfidf_model_file)\n",
    "\n",
    "# tfidf_model = models.tfidfmodel.TfidfModel(corpus, dictionary=dictionary)\n",
    "corpus_df['tf_idf'] = tfidf_model[corpus_df.bow.tolist()]\n",
    "corpus_df[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pregunta** Explicar a qué corresponde la columna tf_idf y por qué es útil en el procesamiento de texto. Mencione sus 2 principales parts, mediante la explicación del puntaje.\n",
    "\n",
    "**Respuesta**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación entrenaremos un modelo LDA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "topic_number = 10\n",
    "\n",
    "lda_model = models.LdaModel(corpus, num_topics=topic_number, id2word=dictionary, passes=5, iterations=200)\n",
    "corpus_df['lda'] = lda_model[corpus_df.bow.tolist()]\n",
    "corpus_df[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pregunta** Explique qué representa la columna lda, ¿qué significan cada tupla de números?\n",
    "\n",
    "**Respuesta**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En la siguiente celda se mostrarán 10 tópicos del modelo LDA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lda_model.print_topics(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pregunta** ¿Qué representa lo impreso en la celda anterior?\n",
    "\n",
    "**Respuesta**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pregunta** A su parecer, ¿son buenos los tópicos encontrados por el modelo? ¿cómo se podrían mejorar?\n",
    "\n",
    "**Respuesta**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Generar Recomendaciones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta sección se implementan las funciones necesarias para poder generar recomendaciones dado lo que un usuario ha consumido. De manera artificial, se samplearán 3 documentos aleatorios que representarán al usuario objetivo (`sample`). Luego tendrás que generar diferentes recomendaciones y evaluar los resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Random user\n",
    "\n",
    "samples = corpus_df.sample(3)\n",
    "\n",
    "for n, (ix, paper) in enumerate(samples.iterrows()):\n",
    "    idx, title, abstract, bow, tf_idf, lda = paper\n",
    "    print('%d) %s' % (n+1, title))\n",
    "    print('')\n",
    "    print(abstract)\n",
    "    print('\\n' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Recommendation functions\n",
    "\n",
    "N = len(dictionary)\n",
    "\n",
    "def to_sparse(matrix):\n",
    "    return csr_matrix([gensim.matutils.sparse2full(row, length=N) for row in matrix]) \n",
    "\n",
    "def make_recommendations(model, metric, neighbors):\n",
    "    M = len(corpus)\n",
    "\n",
    "    X = to_sparse(corpus_df[model].tolist())\n",
    "    document_index = NearestNeighbors(n_neighbors=(neighbors + 1), algorithm='brute', metric=metric).fit(X)\n",
    "    return document_index\n",
    "\n",
    "def print_recommendations(indexes, model):\n",
    "    for n, (ix, paper) in enumerate(samples.iterrows()):\n",
    "        dists, neighbors = indexes.kneighbors([gensim.matutils.sparse2full(paper[model],length=N)])\n",
    "        print(paper['title'])\n",
    "        print('')\n",
    "        print('Documentos cercanos: ')\n",
    "        i = 1\n",
    "        for neighbour in neighbors[0]:\n",
    "            if ix != neighbour:\n",
    "                line = str(i) + \". \" + corpus_df.iloc[neighbour]['title']\n",
    "                print(line)\n",
    "                i+=1\n",
    "        print('\\n')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación deberá utilizar las funciones implementadas anteriormente para generar nuevas recomendaciones variando los parámetros del modelo. Agregue nuevas celdas para cada implementación y/o pregunta."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Pregunta** Ejecute el modelo utilizando como representación `tf-idf` y métrica de distancia euclideana. Modifique el parámetro nearest_neighbors a [5, 10, 20]. ¿qué efecto tiene el modelo en las recomendaciones observadas?\n",
    "\n",
    "**Respuesta**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pregunta** Eligiendo un valor fijo para nearest neighbors y utilizando representación `tf-idf`, ejecute el modelo con métrica de distancia _cosine_.¿Qué efecto tiene la métrica de distancia en las recomendaciones observadas?\n",
    "\n",
    "**Respuesta**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pregunta** Eligiendo un valor fijo de nearest_neighbors y modelo _lda_ ¿Qué efecto tiene el usar LDA versus TF-IDF en las recomendaciones observadas?\n",
    "\n",
    "**Respuesta**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pregunta** Pruebe nuevamente con LDA usando sólo 5 tópicos ¿qué efecto tiene el número de tópicos en las recomendaciones observadas?\n",
    "\n",
    "**Respuesta**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Recommendation example\n",
    "# \n",
    "# doc_idx = make_recommendations('tf_idf', 'euclidean', 5)\n",
    "# print_recommendations(doc_idx, 'tf_idf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entregable\n",
    "\n",
    "Una vez completado el laboratorio y respondido las preguntas deberán exportar este archivo en formato `html` y subir a la plataforma _Moodle_.\n",
    "\n",
    "Para exportar este archivo deben ir a `File > Donwload as > HTML (.html)`\n",
    "\n",
    "Si tienen algún problema o duda enviar mail a **dparra [at] ing [dot] puc [dot] cl** o **slarrain [at] uc [dot] cl** anteponiendo [Diplomada Bog Data] en el asunto."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "recsys-class",
   "language": "python",
   "name": "recsys-class"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
